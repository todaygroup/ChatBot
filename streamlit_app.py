import streamlit as st
from openai import OpenAI

st.set_page_config(page_title="Chatbot (Improved)", page_icon="ğŸ’¬")

# --- í—¤ë” ---
st.title("ğŸ’¬ Chatbot (Improved)")
st.write(
    "Streamlit + OpenAI ì˜ˆì‹œ ì•±ì…ë‹ˆë‹¤. ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸/íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆì–´ìš”.\n"
    "í”„ë¡œë•ì…˜ì—ì„  `.streamlit/secrets.toml`ì— API í‚¤ë¥¼ ì €ì¥í•˜ëŠ” ë°©ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
)

# --- API í‚¤ ---
openai_api_key = st.secrets.get("OPENAI_API_KEY", "")
if not openai_api_key:
    openai_api_key = st.text_input("OpenAI API Key", type="password")

if not openai_api_key:
    st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
    st.stop()

# --- í´ë¼ì´ì–¸íŠ¸ ---
client = OpenAI(api_key=openai_api_key)

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •")
    model = st.selectbox(
        "Model",
        options=["gpt-4o-mini", "gpt-4o", "gpt-5"],  # í™˜ê²½ì— ë§ê²Œ ì¡°ì •
        index=0
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.7, 0.1)
    max_tokens = st.slider("Max output tokens", 128, 4096, 1024, 64)
    HISTORY_WINDOW = st.slider("History window (messages)", 4, 40, 15, 1)

    st.caption("Tip: 4o/5 ê³„ì—´ ìµœì‹  ëª¨ë¸ ê¶Œì¥. ì œí’ˆ/ëª¨ë¸ ì•ˆë‚´ëŠ” OpenAI ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.")

    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
SYSTEM_PROMPT = (
    "You are a helpful, concise assistant for a consulting/marketing professional. "
    "Answer in Korean unless the user asks for another language."
)

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]

# --- ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ ---
for message in st.session_state.messages:
    if message["role"] == "system":
        continue
    with st.chat_message(message["role"], avatar="ğŸ¤–" if message["role"]=="assistant" else "ğŸ‘¤"):
        st.markdown(message["content"])

# --- ì…ë ¥ & ì‘ë‹µ ---
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥/í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    try:
        # íˆìŠ¤í† ë¦¬ ì ˆë‹¨(ì‹œìŠ¤í…œ+ìµœê·¼ ëŒ€í™”)
        payload = []
        sys = [m for m in st.session_state.messages if m["role"] == "system"][:1]
        rest = [m for m in st.session_state.messages if m["role"] in ("user", "assistant")][-HISTORY_WINDOW:]
        payload.extend(sys + rest)

        # --- (A) Chat Completions ìŠ¤íŠ¸ë¦¬ë° ---
        stream = client.chat.completions.create(
            model=model,
            messages=[{"role": m["role"], "content": m["content"]} for m in payload],
            temperature=temperature,
            max_tokens=max_tokens,
            stream=True,
        )

        # --- (B) Responses API ìŠ¤íŠ¸ë¦¬ë°ì„ ì“°ë ¤ë©´ ì•„ë˜ë¡œ êµì²´ ---
        # with client.responses.stream(
        #     model=model,
        #     input=[{"role": "system", "content": SYSTEM_PROMPT}] + [{"role": m["role"], "content": m["content"]} for m in rest],
        #     temperature=temperature,
        #     max_output_tokens=max_tokens,
        # ) as stream_responses:
        #     # ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ deltaë§Œ ì¶”ì¶œí•´ ë˜‘ê°™ì´ full_textë¡œ ëˆ„ì  í›„ ì €ì¥

        # ìŠ¤íŠ¸ë¦¼ ì¶œë ¥ & ë²„í¼ë§
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            full_text = ""
            for chunk in stream:
                delta = chunk.choices[0].delta.get("content", "")
                if delta:
                    full_text += delta
                    st.write(delta, unsafe_allow_html=True)
        st.session_state.messages.append({"role": "assistant", "content": full_text})

    except Exception as e:
        st.error(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
