# app.py
import streamlit as st
from openai import OpenAI

# (ì„ íƒ) httpx ì˜ˆì™¸ë¥¼ ì„¸ë¶„í™”í•´ ì¡ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
try:
    from httpx import HTTPStatusError, ConnectError, ReadTimeout
except Exception:
    HTTPStatusError = ConnectError = ReadTimeout = Exception

# -------- Streamlit ê¸°ë³¸ ì„¤ì • --------
st.set_page_config(page_title="Chatbot (Improved)", page_icon="ğŸ’¬")

st.title("ğŸ’¬ Chatbot (Improved)")
st.write(
    "Streamlit + OpenAI ì˜ˆì‹œ ì•±ì…ë‹ˆë‹¤. ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸/íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n"
    "í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„  `.streamlit/secrets.toml`ì˜ `OPENAI_API_KEY` ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
)

# -------- API í‚¤ ë¡œë”© --------
# 1ìˆœìœ„: secrets.toml, 2ìˆœìœ„: ì‚¬ìš©ì ì…ë ¥
openai_api_key = st.secrets.get("OPENAI_API_KEY", "")
if not openai_api_key:
    openai_api_key = st.text_input("OpenAI API Key", type="password")

if not openai_api_key:
    st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
    st.stop()

# -------- OpenAI í´ë¼ì´ì–¸íŠ¸ --------
client = OpenAI(api_key=openai_api_key)

# -------- ì‚¬ì´ë“œë°”: ì„¤ì • --------
with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •")
    model = st.selectbox(
        "Model",
        options=["gpt-4o-mini", "gpt-4o", "gpt-5"],  # ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹  ëª¨ë¸ë¡œ ì¡°ì •
        index=0,
        help="ìµœì‹  ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.7, 0.1)
    max_tokens = st.slider("Max output tokens", 128, 4096, 1024, 64)
    history_window = st.slider("History window (messages)", 4, 40, 15, 1,
                               help="ìµœê·¼ Nê°œì˜ ëŒ€í™”ë§Œ ëª¨ë¸ì— ë³´ëƒ…ë‹ˆë‹¤(ë¹„ìš©/ì†ë„ ìµœì í™”).")
    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()

# -------- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” --------
SYSTEM_PROMPT = (
    "You are a helpful, concise assistant for a consulting/marketing professional. "
    "Answer in Korean unless the user asks for another language."
)

if "messages" not in st.session_state:
    # system ë©”ì‹œì§€ëŠ” íˆìŠ¤í† ë¦¬ ë§¨ ì•ì— í•œ ë²ˆë§Œ
    st.session_state.messages = [{"role": "system", "content": SYSTEM_PROMPT}]

# -------- ê¸°ì¡´ ë©”ì‹œì§€ ë Œë”ë§ --------
for m in st.session_state.messages:
    if m["role"] == "system":
        continue
    with st.chat_message(m["role"], avatar="ğŸ¤–" if m["role"] == "assistant" else "ğŸ‘¤"):
        st.markdown(m["content"])

# -------- ì…ë ¥ & ì‘ë‹µ --------
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ + í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    try:
        # 2) ëª¨ë¸ì— ì „ë‹¬í•  í˜ì´ë¡œë“œ(ì‹œìŠ¤í…œ 1ê°œ + ìµœê·¼ history_windowê°œ)
        sys = [m for m in st.session_state.messages if m["role"] == "system"][:1]
        rest = [m for m in st.session_state.messages if m["role"] in ("user", "assistant")][-history_window:]
        payload = sys + rest

        # 3) Chat Completions ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
        stream = client.chat.completions.create(
            model=model,
            messages=[{"role": m["role"], "content": m["content"]} for m in payload],
            temperature=temperature,
            max_tokens=max_tokens,
            stream=True,
        )

        # 4) ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì‹  ë° ëˆ„ì  í‘œì‹œ (ChoiceDelta.content ì‚¬ìš©!)
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            full_text = ""
            placeholder = st.empty()
            for chunk in stream:
                # deltaëŠ” ê°ì²´ì´ë¯€ë¡œ .get()ì´ ì•„ë‹ˆë¼ ì†ì„± ì ‘ê·¼ì„ ì‚¬ìš©
                delta = chunk.choices[0].delta
                piece = getattr(delta, "content", "") or ""
                if piece:
                    full_text += piece
                    # ëˆ„ì  ë Œë”ë§: ê¹œë¹¡ì„ ì ê³  ë³µì› ì‰¬ì›€
                    placeholder.markdown(full_text)
            # (ì„ íƒ) finish_reason í™•ì¸ ê°€ëŠ¥:
            # finish = chunk.choices[0].finish_reason if hasattr(chunk.choices[0], "finish_reason") else None

        # 5) ì„¸ì…˜ì— ì–´ì‹œìŠ¤í„´íŠ¸ ì „ì²´ ì‘ë‹µ ì €ì¥
        st.session_state.messages.append({"role": "assistant", "content": full_text})

    except HTTPStatusError as e:
        st.error(f"API ì˜¤ë¥˜({getattr(e.response, 'status_code', 'unknown')}): {str(e)[:300]}")
    except (ConnectError, ReadTimeout):
        st.error("ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œë¡œ ìš”ì²­ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

"""
# ì°¸ê³ 
- ì´ ì˜ˆì‹œëŠ” OpenAI Chat Completions ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- Responses API(ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°)ë¡œ ì „í™˜í•˜ë ¤ë©´, ì•„ë˜ íŒ¨í„´ì„ ì°¸ê³ í•´ êµì²´í•˜ì„¸ìš”.

# Responses API ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì‹œ (ê°œë…)
# with client.responses.stream(
#     model=model,
#     input=[{"role": "system", "content": SYSTEM_PROMPT}] + [{"role": m["role"], "content": m["content"]} for m in rest],
#     temperature=temperature,
#     max_output_tokens=max_tokens,
# ) as s:
#     full_text = ""
#     with st.chat_message("assistant", avatar="ğŸ¤–"):
#         placeholder = st.empty()
#         for event in s:
#             if event.type == "response.output_text.delta":
#                 full_text += event.delta
#                 placeholder.markdown(full_text)
#         s.until_done()
# st.session_state.messages.append({"role": "assistant", "content": full_text})
"""
